{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MLlib with Python 3 in Docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonMLlib\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "Notes on libraries:\n",
    "\n",
    "* Use VectorAssembler to convert df columns to features column. Notes [here](http://stackoverflow.com/questions/37574833/create-labledpoints-from-spark-dataframe-how-to-pass-list-of-names-to-vectoras).\n",
    "* Pipeline example with regression [here](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/32296485791277/4041455208424802/2883572398008418/latest.html?utm_campaign=2016%20Spark%20Summit%20West&utm_medium=social&utm_source=slide).\n",
    "* We used cast and withColumn to convert the column types. Cannot directly assign dataframe column. Sample code [here](http://stackoverflow.com/questions/32284620/how-to-change-a-dataframe-column-from-string-type-to-double-type-in-pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- sqft_living: string (nullable = true)\n",
      " |-- sqft_lot: string (nullable = true)\n",
      " |-- floors: string (nullable = true)\n",
      " |-- waterfront: string (nullable = true)\n",
      " |-- view: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sqft_above: string (nullable = true)\n",
      " |-- sqft_basement: string (nullable = true)\n",
      " |-- yr_built: string (nullable = true)\n",
      " |-- yr_renovated: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- sqft_living15: string (nullable = true)\n",
      " |-- sqft_lot15: string (nullable = true)\n",
      "\n",
      "+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|        id|           date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
      "+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|7129300520|20141013T000000|221900|       3|        1|       1180|    5650|     1|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n",
      "|6414100192|20141209T000000|538000|       3|     2.25|       2570|    7242|     2|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n",
      "|5631500400|20150225T000000|180000|       2|        1|        770|   10000|     1|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n",
      "|2487200875|20141209T000000|604000|       4|        3|       1960|    5000|     1|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n",
      "|1954400510|20150218T000000|510000|       3|        2|       1680|    8080|     1|         0|   0|        3|    8|      1680|            0|    1987|           0|  98074|47.6168|-122.045|         1800|      7503|\n",
      "+----------+---------------+------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('home_data.csv', header=True)\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- sqft_living: double (nullable = true)\n",
      " |-- sqft_lot: string (nullable = true)\n",
      " |-- floors: string (nullable = true)\n",
      " |-- waterfront: string (nullable = true)\n",
      " |-- view: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sqft_above: string (nullable = true)\n",
      " |-- sqft_basement: string (nullable = true)\n",
      " |-- yr_built: string (nullable = true)\n",
      " |-- yr_renovated: string (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- sqft_living15: string (nullable = true)\n",
      " |-- sqft_lot15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"price\", df[\"price\"].cast(DoubleType()))\\\n",
    "                   .withColumn(\"sqft_living\", df[\"sqft_living\"].cast(DoubleType()))\\\n",
    "                   .withColumn(\"zipcode\", df[\"zipcode\"].cast(IntegerType()))\n",
    "                \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate Model\n",
    "Notes:\n",
    "* Model evaluation values like p-value from model summary object. Code sample [here](https://home.apache.org/~pwendell/spark-nightly/spark-branch-2.0-docs/latest/ml-classification-regression.html#generalized-linear-regression)\n",
    "* Prediction values come from an evaluator object. Code sample [here](https://home.apache.org/~pwendell/spark-nightly/spark-branch-2.0-docs/latest/ml-classification-regression.html#decision-tree-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total data is 21613, the training is 15089 and the test is 6524\n"
     ]
    }
   ],
   "source": [
    "(trainData, testData) = df.randomSplit(seed=123, weights=[0.7,0.3])\n",
    "print(\"The total data is {}, the training is {} and the test is {}\"\\\n",
    "      .format(df.count(), trainData.count(), testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = VectorAssembler(inputCols=[trainData.columns[5]], outputCol=\"features\")\n",
    "glr = GeneralizedLinearRegression(labelCol=\"price\", family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "simplePipeline = Pipeline(stages=[vectorizer, glr])\n",
    "model = simplePipeline.fit(trainData)\n",
    "\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "#print(\"AIC: \" + str(model.aic))\n",
    "#print(\"Coefficient Standard Errors: \" + str(model.coefficientStandardErrors))\n",
    "#print(\"T Values: \" + str(model.tValues))\n",
    "#print(\"P Values: \" + str(model.pValues))\n",
    "#print(\"Deviance Residuals: \")\n",
    "#model.residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+\n",
      "|       prediction|   price|features|\n",
      "+-----------------+--------+--------+\n",
      "| 631905.464483257|300000.0|[2400.0]|\n",
      "|536533.7868902887|647500.0|[2060.0]|\n",
      "|368230.8264321095|400000.0|[1460.0]|\n",
      "|671176.1552568321|487000.0|[2540.0]|\n",
      "|514093.3921625315|239000.0|[1980.0]|\n",
      "+-----------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE is: 262008.1665352019\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"price\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE is: {}\".format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
